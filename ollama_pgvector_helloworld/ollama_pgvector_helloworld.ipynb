{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello pgvector: Create, store and query Ollama embeddings in PostgreSQL using pgvector\n",
    "\n",
    "This notebook will teach you:\n",
    "- How to create embeddings from content using a Local Ollama server.\n",
    "- How to use PostgreSQL as a vector database and store embeddings data in it using pgvector.\n",
    "- How to use embeddings retrieved from a vector database to augment LLM generation. \n",
    "\n",
    "We'll be using the example of creating a chatbot to answer questions about Timescale use cases, referencing content from the Timescale Developer Q+A blog posts. \n",
    "\n",
    "This is a great first step to building something like chatbot that can reference a company knowledge base or developer docs.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook uses a PostgreSQL database with pgvector installed that's hosted on Timescale. You can create your own cloud PostgreSQL database in minutes [at this link](https://console.cloud.timescale.com/signup) to follow along. You can also use a local PostgreSQL database if you prefer.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "- Setup Ollama \n",
    "    - `docker compose up -d`\n",
    "    - `docker exec ollama ollama pull nomic-embed-text`\n",
    "    - `docker exec ollama ollama pull llama3.2`\n",
    "- Install Python\n",
    "- Install and configure a python virtual environment. We recommend [Pyenv](https://github.com/pyenv/pyenv)\n",
    "- Install the requirements for this notebook using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.1.2)\n",
      "Requirement already satisfied: tiktoken in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: psycopg2-binary in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.9.10)\n",
      "Requirement already satisfied: pgvector in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.3.5)\n",
      "Requirement already satisfied: python-dotenv in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from tiktoken->-r requirements.txt (line 3)) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from tiktoken->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/git/vector-cookbook/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 3)) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tiktoken\n",
    "import psycopg2\n",
    "import ast\n",
    "import pgvector\n",
    "import math\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\").strip(\"'\\\"\")\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\").strip(\"'\\\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Create Embeddings\n",
    "First, we'll create embeddings using a Local Ollama server API on some text we want to augment our LLM with.\n",
    "In this example, we'll use content from the Timescale blog about real world use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How a Data Scientist Is Building a Time-Series...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-a-data-scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How Conserv Safeguards History: Building an En...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-conserv-saf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Messari Uses Data to Open the Cryptoeconom...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-messari-use...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How to Build a Weather Station With Elixir, Ne...   \n",
       "1  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "2  How a Data Scientist Is Building a Time-Series...   \n",
       "3  How Conserv Safeguards History: Building an En...   \n",
       "4  How Messari Uses Data to Open the Cryptoeconom...   \n",
       "\n",
       "                                             content  \\\n",
       "0  This is an installment of our “Community Membe...   \n",
       "1  This is an installment of our “Community Membe...   \n",
       "2  This is an installment of our “Community Membe...   \n",
       "3  This is an installment of our “Community Membe...   \n",
       "4  This is an installment of our “Community Membe...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.timescale.com/blog/how-to-build-a-...  \n",
       "1  https://www.timescale.com/blog/cloudquery-on-u...  \n",
       "2  https://www.timescale.com/blog/how-a-data-scie...  \n",
       "3  https://www.timescale.com/blog/how-conserv-saf...  \n",
       "4  https://www.timescale.com/blog/how-messari-use...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('blog_posts_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Calculate cost of embedding data\n",
    "It's usually a good idea to calculate how much creating embeddings for your selected content will cost.\n",
    "We use a number of helper functions to calculate a cost estimate before creating the embeddings to help us avoid surprises.\n",
    "\n",
    "For this toy example, since we're using a small dataset, the total cost will be less than $0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to help us create the embeddings\n",
    "\n",
    "# Helper func: calculate number of tokens\n",
    "def num_tokens_from_string(string: str, encoding_name = \"cl100k_base\") -> int:\n",
    "    if not string:\n",
    "        return 0\n",
    "    # Returns the number of tokens in a text string\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "# Helper function: calculate length of essay\n",
    "def get_essay_length(essay):\n",
    "    word_list = essay.split()\n",
    "    num_words = len(word_list)\n",
    "    return num_words\n",
    "\n",
    "# Helper function: calculate cost of embedding num_tokens\n",
    "# Just to check how much money we are saving!\n",
    "# Assumes we're using the text-embedding-ada-002 model\n",
    "def get_embedding_cost(num_tokens):\n",
    "    return num_tokens/1000*0.00002\n",
    "\n",
    "# Helper function: calculate total cost of embedding all content in the dataframe\n",
    "def get_total_embeddings_cost():\n",
    "    total_tokens = 0\n",
    "    for i in range(len(df.index)):\n",
    "        text = df['content'][i]\n",
    "        token_len = num_tokens_from_string(text)\n",
    "        total_tokens = total_tokens + token_len\n",
    "    total_cost = get_embedding_cost(total_tokens)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated price to embed this content = $0.00120356\n"
     ]
    }
   ],
   "source": [
    "# quick check on total token amount for price estimation\n",
    "total_cost = get_total_embeddings_cost()\n",
    "print(\"estimated price to embed this content = $\" + str(total_cost))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create smaller chunks of content\n",
    "A Local Ollama server API has a limit to the maximum amount of tokens it create create an embedding for in a single request. To get around this limit we'll break up our text into smaller chunks. In general its a best practice to create embeddings of a certain size in order to get better retrieval. For our purposes, we'll aim for chunks of around 512 tokens each."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you prefer to skip this step, you can use use the provided file: blog_data_and_embeddings.csv which contains the data and embeddings that you'll generate in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for chunked content and embeddings\n",
    "new_list = []\n",
    "# Split up the text into token sizes of around 512 tokens\n",
    "for i in range(len(df.index)):\n",
    "    text = df['content'][i]\n",
    "    token_len = num_tokens_from_string(text)\n",
    "    if token_len <= 512:\n",
    "        new_list.append([df['title'][i], df['content'][i], df['url'][i], token_len])\n",
    "    else:\n",
    "        # add content to the new list in chunks\n",
    "        start = 0\n",
    "        ideal_token_size = 512\n",
    "        # 1 token ~ 3/4 of a word\n",
    "        ideal_size = int(ideal_token_size // (4/3))\n",
    "        end = ideal_size\n",
    "        #split text by spaces into words\n",
    "        words = text.split()\n",
    "\n",
    "        #remove empty spaces\n",
    "        words = [x for x in words if x != ' ']\n",
    "\n",
    "        total_words = len(words)\n",
    "        \n",
    "        #calculate iterations\n",
    "        chunks = total_words // ideal_size\n",
    "        if total_words % ideal_size != 0:\n",
    "            chunks += 1\n",
    "        \n",
    "        new_content = []\n",
    "        for j in range(chunks):\n",
    "            if end > total_words:\n",
    "                end = total_words\n",
    "            new_content = words[start:end]\n",
    "            new_content_string = ' '.join(new_content)\n",
    "            new_content_token_len = num_tokens_from_string(new_content_string)\n",
    "            if new_content_token_len > 0:\n",
    "                new_list.append([df['title'][i], new_content_string, df['url'][i], new_content_token_len])\n",
    "            start += ideal_size\n",
    "            end += ideal_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: get embeddings for a text\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_embeddings(text):\n",
    "\n",
    "    url = f\"http://{OLLAMA_HOST}:11434/api/embeddings\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"nomic-embed-text\",\n",
    "        \"prompt\": text.replace(\"\\n\", \" \")\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"embedding\"]\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code}, {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='192.168.51.12', port=11434): Max retries exceeded with url: /api/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x713468ca1640>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/connection.py:441\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/http/client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m \n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/http/client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/connection.py:279\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/connection.py:214\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x713468ca1640>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='192.168.51.12', port=11434): Max retries exceeded with url: /api/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x713468ca1640>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(new_list)):\n\u001b[1;32m      3\u001b[0m     text \u001b[38;5;241m=\u001b[39m new_list[i][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     new_list[i]\u001b[38;5;241m.\u001b[39mappend(embedding)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a new dataframe from the list\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[115], line 18\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      9\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnomic-embed-text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m }\n\u001b[0;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/git/vector-cookbook/.venv/lib/python3.12/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='192.168.51.12', port=11434): Max retries exceeded with url: /api/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x713468ca1640>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "# Create embeddings for each piece of content\n",
    "for i in range(len(new_list)):\n",
    "    text = new_list[i][1]\n",
    "    embedding = get_embeddings(text)\n",
    "    new_list[i].append(embedding)\n",
    "\n",
    "# Create a new dataframe from the list\n",
    "df_new = pd.DataFrame(new_list, columns=['title', 'content', 'url', 'tokens', 'embeddings'])\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe with embeddings as a CSV file\n",
    "df_new.to_csv('blog_data_and_embeddings.csv', index=False)\n",
    "# It may also be useful to save as a json file, but we won't use this in the tutorial\n",
    "df_new.to_json('blog_data_and_embeddings.json') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Store embeddings with pgvector\n",
    "In this section, we'll store our embeddings and associated metadata. \n",
    "\n",
    "We'll use PostgreSQL as a vector database, with the pgvector extension. \n",
    "\n",
    "You can create a cloud PostgreSQL database for free on [Timescale](https://console.cloud.timescale.com/signup) or use a local PostgreSQL database for this step."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Connect to and configure your vector database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL database in Timescale using connection string\n",
    "conn = psycopg2.connect(DATABASE_URL)\n",
    "cur = conn.cursor()\n",
    "\n",
    "#install pgvector \n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "conn.commit()\n",
    "\n",
    "#install pgvectorscale \n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;\")\n",
    "conn.commit()\n",
    "\n",
    "# Register the vector type with psycopg2\n",
    "register_vector(conn)\n",
    "\n",
    "# Create table to store embeddings and metadata\n",
    "table_create_command = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS embeddings (\n",
    "            id bigserial primary key, \n",
    "            title text,\n",
    "            url text,\n",
    "            content text,\n",
    "            tokens integer,\n",
    "            embedding vector(768)\n",
    "            );\n",
    "            \"\"\"\n",
    "\n",
    "cur.execute(table_create_command)\n",
    "cur.close()\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Uncomment and execute the following code only if you need to read the embeddings and metadata from the provided CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pd.read_csv('blog_data_and_embeddings.csv')\\ntitles = df['title']\\nurls = df['url']\\ncontents = df['content']\\ntokens = df['tokens']\\nembeds = [list(map(float, ast.literal_eval(embed_str))) for embed_str in df['embeddings']]\\n\\ndf_new = pd.DataFrame({\\n    'title': titles,\\n    'url': urls,\\n    'content': contents,\\n    'tokens': tokens,\\n    'embeddings': embeds\\n})\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment and execute this cell only if you need to read the blog data and embeddings from the provided CSV file\n",
    "# Otherwise, skip to next cell\n",
    "'''\n",
    "df = pd.read_csv('blog_data_and_embeddings.csv')\n",
    "titles = df['title']\n",
    "urls = df['url']\n",
    "contents = df['content']\n",
    "tokens = df['tokens']\n",
    "embeds = [list(map(float, ast.literal_eval(embed_str))) for embed_str in df['embeddings']]\n",
    "\n",
    "df_new = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'url': urls,\n",
    "    'content': contents,\n",
    "    'tokens': tokens,\n",
    "    'embeddings': embeds\n",
    "})\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Ingest and store vector data into PostgreSQL using pgvector\n",
    "In this section, we'll batch insert our embeddings and metadata into PostgreSQL and also create an index to help speed up search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_vector(conn)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>501</td>\n",
       "      <td>[0.3103351891040802, 0.2868889272212982, -2.38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>capture weather and environmental data. In all...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>512</td>\n",
       "      <td>[0.4867981970310211, 1.2176804542541504, -3.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Build a Weather Station With Elixir, Ne...</td>\n",
       "      <td>command in their database migration:SELECT cre...</td>\n",
       "      <td>https://www.timescale.com/blog/how-to-build-a-...</td>\n",
       "      <td>374</td>\n",
       "      <td>[0.6124968528747559, 1.4722315073013306, -3.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>This is an installment of our “Community Membe...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>519</td>\n",
       "      <td>[-0.25388479232788086, 1.5728431940078735, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CloudQuery on Using PostgreSQL for Cloud Asset...</td>\n",
       "      <td>Architecture with CloudQuery SDK- Writing plug...</td>\n",
       "      <td>https://www.timescale.com/blog/cloudquery-on-u...</td>\n",
       "      <td>511</td>\n",
       "      <td>[1.7953698635101318, 2.0240869522094727, -2.54...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How to Build a Weather Station With Elixir, Ne...   \n",
       "1  How to Build a Weather Station With Elixir, Ne...   \n",
       "2  How to Build a Weather Station With Elixir, Ne...   \n",
       "3  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "4  CloudQuery on Using PostgreSQL for Cloud Asset...   \n",
       "\n",
       "                                             content  \\\n",
       "0  This is an installment of our “Community Membe...   \n",
       "1  capture weather and environmental data. In all...   \n",
       "2  command in their database migration:SELECT cre...   \n",
       "3  This is an installment of our “Community Membe...   \n",
       "4  Architecture with CloudQuery SDK- Writing plug...   \n",
       "\n",
       "                                                 url  tokens  \\\n",
       "0  https://www.timescale.com/blog/how-to-build-a-...     501   \n",
       "1  https://www.timescale.com/blog/how-to-build-a-...     512   \n",
       "2  https://www.timescale.com/blog/how-to-build-a-...     374   \n",
       "3  https://www.timescale.com/blog/cloudquery-on-u...     519   \n",
       "4  https://www.timescale.com/blog/cloudquery-on-u...     511   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.3103351891040802, 0.2868889272212982, -2.38...  \n",
       "1  [0.4867981970310211, 1.2176804542541504, -3.53...  \n",
       "2  [0.6124968528747559, 1.4722315073013306, -3.97...  \n",
       "3  [-0.25388479232788086, 1.5728431940078735, -1....  \n",
       "4  [1.7953698635101318, 2.0240869522094727, -2.54...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the dataframe structure\n",
    "df_new.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch insert embeddings using psycopg2's ```execute_values()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch insert embeddings and metadata from dataframe into PostgreSQL database\n",
    "\n",
    "# Prepare the list of tuples to insert\n",
    "data_list = [(row['title'], row['url'], row['content'], int(row['tokens']), np.array(row['embeddings'])) for index, row in df_new.iterrows()]\n",
    "# Use execute_values to perform batch insertion\n",
    "execute_values(cur, \"INSERT INTO embeddings (title, url, content, tokens, embedding) VALUES %s\", data_list)\n",
    "# Commit after we insert all embeddings\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check by running some simple queries against the embeddings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vector records in table:  129 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) as cnt FROM embeddings;\")\n",
    "num_records = cur.fetchone()[0]\n",
    "print(\"Number of vector records in table: \", num_records,\"\\n\")\n",
    "# Correct output should be 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First record in table:  [(1, 'How to Build a Weather Station With Elixir, Nerves, and TimescaleDB', 'https://www.timescale.com/blog/how-to-build-a-weather-station-with-elixir-nerves-and-timescaledb/', 'This is an installment of our “Community Member Spotlight” series, where we invite our customers to share their work, shining a light on their success and inspiring others with new ways to use technology to solve problems.In this edition,Alexander Koutmos, author of the Build a Weather Station with Elixir and Nerves book, joins us to share how he uses Grafana and TimescaleDB to store and visualize weather data collected from IoT sensors.About the teamThe bookBuild a Weather Station with Elixir and Nerveswas a joint effort between Bruce Tate, Frank Hunleth, and me.I have been writing software professionally for almost a decade and have been working primarily with Elixir since 2016. I currently maintain a few Elixir libraries onHexand also runStagira, a software consultancy company.Bruce Tateis a kayaker, programmer, and father of two from Chattanooga, Tennessee. He is the author of more than ten books and has been around Elixir from the beginning. He is the founder ofGroxio, a company that trains Elixir developers.Frank Hunlethis an embedded systems programmer, OSS maintainer, and Nerves core team member. When not in front of a computer, he loves running and spending time with his family.About the projectIn the Pragmatic Bookshelf book,Build a Weather Station with Elixir and Nerves, we take a project-based approach and guide the reader to create a Nerves-powered IoT weather station.For those unfamiliar with the Elixir ecosystem,Nervesis an IoT framework that allows you to build and deploy IoT applications on a wide array of embedded devices. At a high level, Nerves allows you to focus on building your project and takes care of a lot of the boilerplate associated with running Elixir on embedded devices.The goal of the book is to guide the reader through the process of building an end-to-end IoT solution for capturing, persisting, and visualizing weather data.Assembled weather station hooked up to development machine.One of the motivating factors for this book was to create a real-world project where readers could get hands-on experience with hardware without worrying too much about the nitty-gritty of soldering components together. Experimenting with hardware can often feel intimidating and confusing, but with Elixir and Nerves, we feel confident that even beginners get comfortable and productive quickly. As a result, in the book, we leverage a Raspberry Pi Zero W along with a few I2C enabled sensors to', 501, array([ 3.10335189e-01,  2.86888927e-01, -2.38160372e+00, -4.50779218e-03,\n",
      "        1.96933270e+00, -3.56094033e-01,  2.79940218e-01, -1.28163248e-01,\n",
      "       -7.79648066e-01, -1.59093249e+00, -5.24521649e-01,  1.33137894e+00,\n",
      "        6.13298535e-01,  1.46138459e-01, -3.82987857e-02,  1.36529237e-01,\n",
      "       -8.27261358e-02, -5.68086326e-01,  1.02249300e+00,  1.50810689e-01,\n",
      "        9.85979795e-01, -2.09111357e+00, -4.80267256e-01,  6.41276598e-01,\n",
      "        5.26054144e-01,  3.21726710e-01,  1.19966662e+00, -2.30505273e-01,\n",
      "       -3.66922230e-01,  3.96322638e-01, -4.22138870e-01, -1.17845452e+00,\n",
      "       -6.27008200e-01, -3.01867761e-02,  5.71757928e-02, -7.24135995e-01,\n",
      "       -4.00583386e-01,  1.52970254e-01, -2.40308300e-01,  1.30933022e+00,\n",
      "       -1.11114049e+00, -3.03874344e-01,  9.83213067e-01, -1.18521595e+00,\n",
      "        1.20546341e+00,  7.66579866e-01,  7.99399376e-01,  6.03655614e-02,\n",
      "        4.48943734e-01, -2.99085736e-01,  2.00556085e-01, -8.40371668e-01,\n",
      "       -1.39734328e-01,  3.06100138e-02,  7.96138585e-01, -1.10022092e+00,\n",
      "       -1.10506535e+00,  1.30507529e-01,  1.64814472e-01,  1.27240717e-02,\n",
      "        1.77571744e-01,  1.84153950e+00, -6.78436875e-01, -2.37907261e-01,\n",
      "        4.18409795e-01,  8.48712146e-01,  3.81365836e-01,  6.34592772e-01,\n",
      "       -1.67750120e-01, -7.43594319e-02,  8.55343580e-01, -3.65671128e-01,\n",
      "        4.86021459e-01,  5.99527121e-01,  1.28006404e-02, -3.25632721e-01,\n",
      "       -1.12529323e-01, -7.61360154e-02,  2.77223855e-01,  6.74715757e-01,\n",
      "        2.31945947e-01, -1.15036964e-01,  9.11555409e-01,  3.95815253e-01,\n",
      "        1.52654743e+00,  7.09218442e-01, -2.53510885e-02,  2.83004671e-01,\n",
      "       -6.41325474e-01,  1.58174157e+00, -9.41791683e-02,  4.62243676e-01,\n",
      "        7.79030442e-01,  1.75130934e-01, -3.40507440e-02,  7.11247325e-01,\n",
      "        3.89957339e-01,  1.08917964e+00, -9.76933002e-01,  4.85767424e-01,\n",
      "       -7.32540786e-01, -1.57659844e-01, -3.78145367e-01, -4.97442842e-01,\n",
      "        7.50279546e-01,  2.19950885e-01,  4.11778301e-01, -4.10197005e-02,\n",
      "        7.97373950e-01, -5.66694081e-01,  3.65609258e-01,  3.65960211e-01,\n",
      "       -3.63130838e-01,  6.35785013e-02,  2.90678650e-01,  6.41998649e-02,\n",
      "        4.63806123e-01, -8.69385153e-02,  3.48624587e-01,  2.55984575e-01,\n",
      "        1.76465303e-01,  4.09976989e-01, -9.60043907e-01,  1.09961390e+00,\n",
      "        3.25251609e-01, -2.60356307e-01, -7.73860455e-01, -1.25092044e-01,\n",
      "       -1.61986724e-02,  1.94995344e-01,  5.45538843e-01, -6.60703659e-01,\n",
      "       -1.06204057e+00,  1.97739601e-01, -7.62251377e-01,  1.10090685e+00,\n",
      "       -1.35776234e+00, -1.18879247e+00,  4.48228180e-01,  3.45890164e-01,\n",
      "       -4.51022476e-01,  2.20819101e-01, -8.72695684e-01, -3.96177381e-01,\n",
      "        2.77553380e-01, -6.68819666e-01, -5.98688960e-01, -2.97592491e-01,\n",
      "       -4.41993177e-02,  1.97729841e-03,  3.59713472e-02, -8.00879747e-02,\n",
      "       -1.78385898e-01,  6.53947771e-01,  1.18442082e+00, -6.85015082e-01,\n",
      "       -5.38838133e-02, -2.14062288e-01,  7.03666985e-01,  2.36931846e-01,\n",
      "        9.61912990e-01,  9.68585834e-02, -6.65174127e-01,  5.61143219e-01,\n",
      "       -1.34664214e+00, -9.54786718e-01, -6.19234622e-01,  9.76108551e-01,\n",
      "        7.11102843e-01,  1.21922088e+00, -1.26760352e+00, -3.61058921e-01,\n",
      "       -5.91879487e-01, -2.91142225e-01,  1.89998984e-01, -7.88912773e-01,\n",
      "       -4.66928899e-01,  1.03852585e-01,  1.19264972e+00, -6.43402517e-01,\n",
      "       -1.50188329e-02,  1.14014216e-01, -1.10000521e-01,  1.25694484e-01,\n",
      "       -7.57576942e-01, -3.26162100e-01,  5.63926399e-01,  2.48949528e-01,\n",
      "       -7.04322338e-01, -2.60889977e-01, -3.37255508e-01,  1.64950043e-01,\n",
      "       -1.27309227e+00, -4.63620096e-01, -1.18839860e-01,  8.74208808e-02,\n",
      "       -1.21965080e-01,  4.71131325e-01,  8.24810505e-01, -2.16221064e-01,\n",
      "        6.98446870e-01, -8.74199748e-01, -7.36498058e-01,  1.48032933e-01,\n",
      "       -4.54250842e-01,  8.97819400e-02,  4.55132842e-01, -2.79605031e-01,\n",
      "        6.98236078e-02, -3.70857060e-01,  9.06013966e-01,  3.23112160e-01,\n",
      "       -6.53161108e-01, -1.03827441e+00,  4.18119073e-01, -1.91379488e-01,\n",
      "        4.05120969e-01, -9.08538699e-01, -7.03997910e-03,  2.06402555e-01,\n",
      "        3.17134649e-01, -2.00568765e-01,  1.26469457e+00,  3.73573720e-01,\n",
      "        8.58528197e-01,  1.15314245e-01, -1.20087075e+00, -4.32054222e-01,\n",
      "       -1.17040843e-01,  4.54423040e-01,  6.89556599e-01, -1.81115299e-01,\n",
      "        1.49729824e+00, -1.30256742e-01,  1.19222477e-01,  7.14553714e-01,\n",
      "       -4.81294990e-01,  4.96902354e-02, -6.68332577e-01, -2.94778734e-01,\n",
      "       -5.69536328e-01,  3.76868397e-01,  4.78841811e-02, -1.67694449e-01,\n",
      "       -1.01514864e+00, -4.70893800e-01,  2.79599428e-01,  3.13738227e-01,\n",
      "        4.08200681e-01,  4.15253699e-01, -2.03206748e-01,  1.96845643e-02,\n",
      "       -3.20451230e-01,  1.82095742e+00, -5.31483829e-01, -8.42210174e-01,\n",
      "        2.70094365e-01,  5.69509268e-01, -3.07506323e-01, -1.19304621e+00,\n",
      "        4.41898018e-01, -1.08807397e+00, -3.07746083e-01,  1.86654091e-01,\n",
      "        4.31878626e-01,  3.05666029e-01, -2.48096690e-01,  4.98393595e-01,\n",
      "       -1.16379574e-01, -9.13677156e-01,  3.16327691e-01,  2.06450507e-01,\n",
      "        2.20945925e-02,  8.35008621e-01,  9.96142328e-02,  1.70422614e-01,\n",
      "        1.28232205e+00,  4.71352667e-01,  3.89367901e-03, -2.02015802e-01,\n",
      "        3.85281682e-01,  4.31773812e-02, -8.15514803e-01,  4.50724602e-01,\n",
      "       -2.78738916e-01,  6.18175030e-01, -5.65993115e-02, -1.25050557e+00,\n",
      "        7.41178811e-01, -3.95379782e-01,  2.10460097e-01, -2.62759864e-01,\n",
      "       -1.20818466e-01, -3.22102249e-01,  5.38493276e-01, -3.13780993e-01,\n",
      "        3.68338972e-01, -4.87277135e-02,  1.23689497e+00,  4.94575202e-01,\n",
      "        1.11196041e+00,  5.89561939e-01,  1.50077558e+00,  2.32153803e-01,\n",
      "       -6.34172633e-02, -1.56791449e+00,  1.38448834e-01, -1.01343431e-01,\n",
      "       -2.12953031e-01,  5.25598824e-01, -3.66659790e-01, -5.25116503e-01,\n",
      "       -6.05430245e-01,  8.98575008e-01, -8.99078310e-01,  3.11793029e-01,\n",
      "       -3.75210010e-02,  2.31952351e-02,  5.21154031e-02,  5.17837524e-01,\n",
      "        6.39241219e-01, -7.17691839e-01,  1.78207949e-01, -1.14785707e+00,\n",
      "        7.21884489e-01,  1.23385549e+00,  7.58623481e-02,  2.72313338e-02,\n",
      "       -9.05289292e-01, -7.15678036e-02,  7.74061382e-02,  7.14361429e-01,\n",
      "        6.16500556e-01, -2.41999090e-01, -1.37480807e+00, -5.11068225e-01,\n",
      "       -1.09548295e+00,  4.41604972e-01, -5.06253839e-01,  1.53323710e+00,\n",
      "        1.20221329e+00, -3.99587095e-01,  2.69109905e-01, -7.70281732e-01,\n",
      "       -2.47197688e-01, -3.19218785e-01, -5.98318458e-01,  3.75390589e-01,\n",
      "       -1.20621234e-01, -1.20104277e+00, -9.53517854e-02, -2.01365009e-01,\n",
      "       -4.91601288e-01,  1.87625103e-02,  7.20174670e-01, -5.34375489e-01,\n",
      "       -1.84993982e+00,  5.95543742e-01, -4.76394832e-01,  1.88531876e-01,\n",
      "       -1.39092833e-01,  5.11111736e-01,  1.10421073e+00, -3.44119877e-01,\n",
      "        5.92197478e-01, -5.26170194e-01, -4.78286371e-02,  6.40788078e-01,\n",
      "        9.43916917e-01, -3.63890111e-01, -4.26196247e-01,  4.62253124e-01,\n",
      "       -7.56551504e-01,  9.33934867e-01,  3.20896387e-01,  3.73984575e-01,\n",
      "       -7.62197495e-01, -1.12228572e+00, -8.42434585e-01,  1.62219965e+00,\n",
      "       -3.70888293e-01, -8.50254953e-01,  2.97582507e-01,  1.53985590e-01,\n",
      "        3.89778882e-01, -1.02309012e+00,  3.29171419e-01, -1.97730362e-02,\n",
      "        1.87389869e-02,  3.43855113e-01, -3.21866989e-01, -8.17336142e-01,\n",
      "       -3.27856869e-01, -4.97308224e-01, -2.38891855e-01, -5.36770225e-01,\n",
      "        4.16845500e-01, -5.72186470e-01, -3.07100832e-01,  6.92688107e-01,\n",
      "       -6.08661175e-01, -8.38025212e-01,  1.17105627e+00, -5.37166633e-02,\n",
      "       -3.03540319e-01,  6.73330665e-01,  2.05549255e-01,  7.53829718e-01,\n",
      "        1.26448166e+00,  5.29081285e-01, -5.13344407e-01,  1.07116961e+00,\n",
      "       -5.00329018e-01, -7.16763437e-01,  4.57891196e-01,  1.51049376e-01,\n",
      "        8.86803627e-01, -4.00881261e-01, -5.15151083e-01,  1.34010911e-01,\n",
      "       -4.58311230e-01,  1.08393049e+00,  2.58070529e-01, -4.94472384e-01,\n",
      "       -8.09985816e-01,  1.27305090e-02,  2.76493877e-01,  4.53080356e-01,\n",
      "        1.31680220e-01, -5.42292893e-01, -1.32262662e-01, -2.94546098e-01,\n",
      "        1.46406388e+00,  1.59912512e-01, -1.75457180e-01, -2.72031948e-02,\n",
      "        8.43105733e-01,  6.32843435e-01, -9.53816116e-01,  2.55033135e-01,\n",
      "        3.92590016e-01, -1.06156938e-01, -2.48218179e-01, -2.73586303e-01,\n",
      "       -2.55842268e-01,  1.25309813e+00,  5.94766557e-01, -2.35340353e-02,\n",
      "        1.24871105e-01,  3.50286156e-01,  6.98212087e-01, -2.28488535e-01,\n",
      "        4.79110003e-01,  1.32224932e-01,  9.25992966e-01, -3.80152911e-01,\n",
      "        1.78722933e-01,  4.51548308e-01,  6.77823901e-01,  3.58199745e-01,\n",
      "        9.20640156e-02, -1.78591087e-01, -6.35410547e-01, -2.83833593e-01,\n",
      "        3.43546778e-01,  4.50709432e-01, -3.65184456e-01,  1.34167597e-01,\n",
      "        4.77789760e-01, -1.83592811e-02, -9.95114326e-01, -1.42555863e-01,\n",
      "        6.01534247e-01,  1.52604401e+00, -7.17158020e-01, -2.86818087e-01,\n",
      "       -1.34130165e-01,  1.50991932e-01, -1.98646665e-01,  6.24604106e-01,\n",
      "       -6.75190538e-02,  1.34500638e-01, -1.05990934e+00, -7.97726929e-01,\n",
      "        1.41772175e+00, -5.62025309e-01, -7.29325652e-01,  4.79858443e-02,\n",
      "       -9.29928124e-02, -3.98656487e-01,  1.48524964e+00,  1.20971346e+00,\n",
      "        5.79425693e-01, -2.91417181e-01, -2.79930204e-01,  3.13729972e-01,\n",
      "       -5.43156385e-01, -1.68345869e-03,  1.33509085e-01,  9.42026734e-01,\n",
      "        3.95865411e-01,  9.63648021e-01,  4.28700030e-01,  7.39268243e-01,\n",
      "        4.52517658e-01, -1.51308322e+00, -4.76183504e-01, -8.92344594e-01,\n",
      "       -4.66098636e-01,  4.95790452e-01, -1.60235095e+00,  2.01353773e-01,\n",
      "        1.38676375e-01,  2.42718756e-01,  2.18252480e-01,  5.19568250e-02,\n",
      "        2.13902265e-01, -1.44065470e-01, -1.41938198e+00,  9.75011349e-01,\n",
      "       -4.38945204e-01, -1.46105444e+00,  5.02974093e-01, -3.29941392e-01,\n",
      "       -1.49422944e+00,  9.98552799e-01, -1.31522310e+00, -8.02987814e-01,\n",
      "        1.07840228e+00, -9.16137621e-02,  5.69501042e-01,  3.69019471e-02,\n",
      "       -6.50289416e-01, -1.22978902e+00, -2.26431176e-01,  4.98921931e-01,\n",
      "       -4.72680241e-01, -4.49007392e-01,  1.16538155e+00,  9.39943850e-01,\n",
      "        2.63445139e-01, -5.24768978e-02,  8.45893994e-02,  1.09709024e+00,\n",
      "        4.74105403e-03, -2.56085187e-01,  6.99932396e-01,  1.09001303e+00,\n",
      "       -6.74272835e-01, -1.65475595e+00,  1.08505535e+00, -1.61359876e-01,\n",
      "        3.97569120e-01, -9.45682749e-02, -2.18481377e-01, -8.56479168e-01,\n",
      "       -6.29908204e-01, -5.16598284e-01, -8.08531269e-02, -6.83460712e-01,\n",
      "        2.59983599e-01,  9.35496092e-01,  2.77893752e-01,  5.90947449e-01,\n",
      "        1.40849382e-01,  3.99411976e-01,  4.00690109e-01,  2.82584429e-01,\n",
      "       -3.86723578e-02,  2.29845285e-01,  3.70993644e-01, -6.01439953e-01,\n",
      "       -4.01297025e-02, -4.58258808e-01,  2.67780989e-01, -6.22844100e-01,\n",
      "        4.29608077e-01,  1.01443458e+00,  1.10868633e-01, -6.31690979e-01,\n",
      "       -1.04645081e-01,  9.68089223e-01,  2.63617784e-02, -9.86678079e-02,\n",
      "        8.65777969e-01,  4.65649933e-01, -3.15937400e-01,  3.25555414e-01,\n",
      "        4.64801878e-01, -8.15103352e-01, -4.81384397e-01, -7.72686422e-01,\n",
      "       -5.51546693e-01, -2.02877685e-01, -4.61912781e-01, -4.00119841e-01,\n",
      "       -7.53123045e-01, -1.46291769e+00, -1.06945431e+00,  2.13709980e-01,\n",
      "        4.81040105e-02, -4.98874128e-01,  2.25305796e-01, -8.23138773e-01,\n",
      "       -3.73526692e-01, -4.14451584e-03,  4.23361778e-01,  1.14345208e-01,\n",
      "       -1.35967538e-01, -9.43628192e-01,  3.35873336e-01, -2.97540784e-01,\n",
      "       -6.24651134e-01, -1.51367164e+00,  8.69238377e-01, -9.93542150e-02,\n",
      "        1.06757545e+00, -1.26669383e+00, -1.63202539e-01, -1.06341660e+00,\n",
      "        2.15132922e-01, -5.55318594e-01, -2.13240564e-01, -2.11268291e-01,\n",
      "        7.08531976e-01,  7.31981024e-02,  1.43801093e-01,  6.74532950e-02,\n",
      "        5.31775832e-01,  9.52447534e-01, -6.45368516e-01,  4.23786700e-01,\n",
      "       -3.50460768e-01, -5.97222596e-02, -2.00091124e-01, -5.92729390e-01,\n",
      "        9.55543697e-01, -1.20405272e-01,  6.44138634e-01,  1.46284509e+00,\n",
      "        1.29249215e+00, -2.13457018e-01, -1.02447724e+00,  5.89765370e-01,\n",
      "       -1.86796814e-01,  4.63388264e-01,  5.00490665e-01,  9.49362040e-01,\n",
      "        7.03515485e-04, -5.74647486e-01,  6.80427790e-01,  9.81938958e-01,\n",
      "        1.07482207e+00, -1.17012553e-01, -5.15637159e-01, -2.32291609e-01,\n",
      "       -2.41061047e-01, -9.04393435e-01, -8.25333655e-01, -7.21423447e-01,\n",
      "        1.40486360e-01, -5.71629941e-01, -5.67999661e-01, -8.80608559e-02,\n",
      "       -4.37998176e-01,  6.00544393e-01,  9.76056755e-02, -1.14796728e-01,\n",
      "       -1.10525715e+00, -9.71842855e-02, -3.95480633e-01,  2.79468030e-01,\n",
      "       -5.92318714e-01, -3.38696986e-01,  2.47762010e-01,  1.68340281e-01,\n",
      "        4.61049110e-01, -3.76068890e-01, -7.61016130e-01, -4.50395286e-01,\n",
      "        1.28811926e-01, -7.69393623e-01,  7.30106950e-01,  9.93878394e-02,\n",
      "       -8.90489280e-01,  4.44472373e-01,  1.21365380e+00, -1.74561128e-01,\n",
      "       -7.77498662e-01, -8.90356481e-01, -4.29177612e-01, -3.54896545e-01,\n",
      "        3.50621164e-01, -3.98617297e-01,  5.24519086e-02,  7.45636746e-02,\n",
      "       -2.07432672e-01,  3.05551946e-01, -5.57172537e-01, -4.24011983e-03,\n",
      "        6.08812809e-01, -2.43026704e-01,  8.58951807e-01,  6.78091764e-01,\n",
      "       -6.56070054e-01, -9.37965810e-02, -7.12474287e-02, -4.07844514e-01,\n",
      "        2.89482296e-01,  2.39613771e-01,  1.48295015e-02,  8.62273812e-01,\n",
      "       -2.12103844e-01, -1.77193016e-01, -8.08268964e-01,  6.99492693e-01,\n",
      "       -1.00516605e+00,  3.40545952e-01, -3.61189485e-01,  8.45536768e-01,\n",
      "       -2.12521389e-01, -3.68092477e-01, -1.27232814e+00,  3.62938829e-02,\n",
      "        7.63842762e-02, -2.49973595e-01,  5.65190852e-01, -5.90284348e-01,\n",
      "        9.02926207e-01, -4.23730135e-01,  7.88666159e-02,  5.08683145e-01,\n",
      "       -4.08416301e-01,  6.98823214e-01, -1.22634411e+00,  3.59098554e-01,\n",
      "        7.08903611e-01, -2.28493735e-01, -1.45619047e+00,  7.00731650e-02,\n",
      "       -7.95781910e-01,  6.26435280e-02, -1.17999125e+00,  2.08505839e-01,\n",
      "       -1.25759184e-01,  4.91518140e-01,  9.50848684e-02,  6.30941451e-01,\n",
      "        5.09109855e-01, -3.80457520e-01,  2.95254350e-01,  3.04597348e-01,\n",
      "       -1.05674338e+00,  1.36853203e-01,  6.11732721e-01, -3.36436272e-01,\n",
      "       -2.25000903e-01,  5.88680983e-01,  1.02135861e+00, -5.79367653e-02,\n",
      "        1.47468781e+00, -1.87312469e-01, -4.29295748e-01,  6.69702828e-01,\n",
      "       -4.72641468e-01, -9.50408220e-01, -7.57978439e-01,  3.86666805e-02],\n",
      "      dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "# print the first record in the table, for sanity-checking\n",
    "cur.execute(\"SELECT * FROM embeddings LIMIT 1;\")\n",
    "records = cur.fetchall()\n",
    "print(\"First record in table: \", records)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create index on embedding column for faster cosine similarity comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index on the data for faster retrieval\n",
    "# this isn't really needed for 129 vectors, but it shows the usage for larger datasets\n",
    "# Note: always create this type of index after you have data already inserted into the DB\n",
    "\n",
    "# for different tuning suggestions check this: https://github.com/timescale/pgvectorscale?tab=readme-ov-file#tuning\n",
    "cur.execute('CREATE INDEX embedding_idx ON embeddings USING diskann (embedding);')\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Nearest Neighbor Search using pgvector\n",
    "\n",
    "In this final part of the tutorial, we will query our embeddings table. \n",
    "\n",
    "We'll showcase an example of RAG: Retrieval Augmented Generation, where we'll retrieve relevant data from our vector database and give it to the LLM as context to use when it generates a response to a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"llama3.2:latest\", temperature=0, max_tokens=1000):\n",
    "    # Ollama API endpoint\n",
    "    url = f\"http://{OLLAMA_HOST}:11434/api/generate\"\n",
    "    \n",
    "    # Prepare the prompt\n",
    "    prompt = \"\"\n",
    "    for message in messages:\n",
    "        role = message[\"role\"]\n",
    "        content = message[\"content\"]\n",
    "        prompt += f\"{role.capitalize()}: {content}\\n\"\n",
    "    \n",
    "    # Prepare the request payload\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "    \n",
    "    # Send the request to Ollama\n",
    "    response = requests.post(url, json=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = json.loads(response.text)\n",
    "        return result[\"response\"]\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code}, {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Get top 3 most similar documents from the database\n",
    "def get_top3_similar_docs(query_embedding, conn):\n",
    "    embedding_array = np.array(query_embedding)\n",
    "    # Register pgvector extension\n",
    "    register_vector(conn)\n",
    "    cur = conn.cursor()\n",
    "    # Get the top 3 most similar documents using the KNN <=> operator\n",
    "    cur.execute(\"SELECT content FROM embeddings ORDER BY embedding <=> %s LIMIT 3\", (embedding_array,))\n",
    "    top3_docs = cur.fetchall()\n",
    "    return top3_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define a prompt for the LLM\n",
    "Here we'll define the prompt we want the LLM to provide a reponse to.\n",
    "\n",
    "We've picked an example relevant to the blog post data stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question about Timescale we want the model to answer\n",
    "input = \"How is Timescale used in IoT?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process input with retrieval of most similar documents from the database\n",
    "def process_input_with_retrieval(user_input):\n",
    "    delimiter = \"```\"\n",
    "\n",
    "    #Step 1: Get documents related to the user input from database\n",
    "    related_docs = get_top3_similar_docs(get_embeddings(user_input), conn)\n",
    "\n",
    "    # Step 2: Get completion from Ollama API\n",
    "    # Set system message to help set appropriate tone and context for model\n",
    "    system_message = f\"\"\"\n",
    "    You are a friendly chatbot. \\\n",
    "    You can answer questions about timescaledb, its features and its use cases. \\\n",
    "    You respond in a concise, technically credible tone. \\\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare messages to pass to model\n",
    "    # We use a delimiter to help the model understand the where the user_input starts and ends\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{user_input}{delimiter}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Relevant Timescale case studies information: \\n {related_docs[0][0]} \\n {related_docs[1][0]} {related_docs[2][0]}\"}   \n",
    "    ]\n",
    "\n",
    "    final_response = get_completion_from_messages(messages)\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is Timescale used in IoT?\n",
      "TimescaleDB is particularly well-suited for IoT projects due to its ability to efficiently handle large amounts of time-stamped sensor data. By leveraging TimescaleDB's performance capabilities, you can reduce latency in queries and improve overall system responsiveness.\n",
      "\n",
      "In the context of IoT, TimescaleDB can be used to store and analyze sensor data from various sources, such as temperature, humidity, pressure, or other environmental factors. The database's ability to compress and aggregate data helps keep table sizes in check, ensuring optimal performance even with growing data volumes.\n",
      "\n",
      "Some potential use cases for TimescaleDB in IoT include:\n",
      "\n",
      "1. Real-time monitoring of environmental conditions\n",
      "2. Predictive maintenance for industrial equipment\n",
      "3. Analyzing sensor data from smart cities or buildings\n",
      "\n",
      "By utilizing TimescaleDB's features and capabilities, you can build efficient and scalable solutions that cater to the unique demands of IoT applications.\n",
      "\n",
      "Would you like to know more about TimescaleDB's performance characteristics or how it compares to other time-series databases?\n"
     ]
    }
   ],
   "source": [
    "response = process_input_with_retrieval(input)\n",
    "print(input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about Edeva and Hopara. How do they use Timescale?\n",
      "Edeva and Hopara are two companies that have successfully implemented TimescaleDB to manage their time-series data. Here's a brief overview of how they use Timescale:\n",
      "\n",
      "**Edeva**\n",
      "\n",
      "Edeva uses TimescaleDB to store and analyze traffic data from their dynamic speed bumps, which contain hundreds of millions of records. They create a materialized view using continuous aggregations, which allows them to efficiently query and visualize their data.\n",
      "\n",
      "The materialized view uses the `timescaledb_experimental.time_bucket_ng` function to bucket time-series data by month, and then applies aggregation functions to calculate percentiles of vehicle speed. This allows Edeva to quickly fetch data for graphs and maps in their analytics platform, EdevaLive.\n",
      "\n",
      "**Hopara**\n",
      "\n",
      "Hopara uses TimescaleDB as the backend database for their IoT project, which involves monitoring temperature and humidity sensors. They connect to TimescaleDB using PHP and Yii 2, and use Qlik Sense for business analytics.\n",
      "\n",
      "Hopara has implemented a data lake integration with TimescaleDB, which allows them to reduce the amount of raw data stored in the database. This integration enables them to efficiently query and analyze their time-series data without overloading the system with too much data.\n",
      "\n",
      "Both Edeva and Hopara have found that using TimescaleDB has greatly improved their ability to work with time-series data, and they are excited to continue building more graphs and map applications using the platform.\n"
     ]
    }
   ],
   "source": [
    "# We can also ask the model questions about specific documents in the database\n",
    "input_2 = \"Tell me about Edeva and Hopara. How do they use Timescale?\"\n",
    "response_2 = process_input_with_retrieval(input_2)\n",
    "print(input_2)\n",
    "print(response_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
